memory=None callbacks=None callback_manager=None verbose=True tags=None metadata=None planner=LLMPlanner(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=ChatPromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, messages=[SystemMessage(content="Let's first understand the problem and devise a plan to solve the problem. Please output the plan starting with the header 'Plan:' and then followed by a numbered list of steps. Please make the plan the minimum number of steps required to accurately complete the task. If the task is a question, the final step should almost always be 'Given the above steps taken, please respond to the users original question'. At the end of your plan, say '<END_OF_PLAN>'", additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), output_parser=PlanningOutputParser(), stop=['<END_OF_PLAN>']) executor=ChainExecutor(chain=AgentExecutor(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, metadata=None, agent=StructuredChatAgent(llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=ChatPromptTemplate(input_variables=['previous_steps', 'current_step', 'agent_scratchpad'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n\nweb_action_identifier: the input for this tool is the user query and the html code of the website, it returns the action to be taken on the website, args: {{{{\'tool_input\': {{{{\'type\': \'string\'}}}}}}}}\nfetch_html_code: this will help fetch the html_code of the page user is currenly viewing, args: {{{{\'tool_input\': {{{{\'type\': \'string\'}}}}}}}}\n\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n\nValid "action" values: "Final Answer" or web_action_identifier, fetch_html_code\n\nProvide only ONE action per $JSON_BLOB, as shown:\n\n```\n{{\n  "action": $TOOL_NAME,\n  "action_input": $INPUT\n}}\n```\n\nFollow this format:\n\nQuestion: input question to answer\nThought: consider previous and subsequent steps\nAction:\n```\n$JSON_BLOB\n```\nObservation: action result\n... (repeat Thought/Action/Observation N times)\nThought: I know what to respond\nAction:\n```\n{{\n  "action": "Final Answer",\n  "action_input": "Final response to human"\n}}\n```\n\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation:.\nThought:', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'current_step', 'previous_steps'], output_parser=None, partial_variables={}, template='Previous steps: {previous_steps}\n\nCurrent objective: {current_step}\n\n{agent_scratchpad}', template_format='f-string', validate_template=True), additional_kwargs={})]), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), output_parser=StructuredChatOutputParserWithRetries(base_parser=StructuredChatOutputParser(), output_fixing_parser=OutputFixingParser(parser=StructuredChatOutputParser(), retry_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, prompt=PromptTemplate(input_variables=['completion', 'error', 'instructions'], output_parser=None, partial_variables={}, template='Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}))), allowed_tools=['web_action_identifier', 'fetch_html_code']), tools=[Tool(name='web_action_identifier', description='the input for this tool is the user query and the html code of the website, it returns the action to be taken on the website', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method WebActionIdentifier._run of WebActionIdentifier(name='web_action_identifier', description='identify the correct element selector and action to take on a given web page', args_schema=<class 'WebActionIdentifier.WebActionSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False)>, coroutine=None), Tool(name='fetch_html_code', description='this will help fetch the html_code of the page user is currenly viewing', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method ReturnHTMLCode._run of ReturnHTMLCode(name='fetch_html_code', description='this will help fetch the html_code of the page user is currenly viewing', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False)>, coroutine=None)], return_intermediate_steps=False, max_iterations=15, max_execution_time=None, early_stopping_method='force', handle_parsing_errors=False, trim_intermediate_steps=-1)) step_container=ListStepContainer(steps=[]) input_key='input' output_key='output'